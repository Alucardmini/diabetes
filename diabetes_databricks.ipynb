{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reproducing and expanding case study of Shvartser posted at Dr. Brownlee's machinelearningmastery.com\n",
      "0.19.1\n"
     ]
    }
   ],
   "source": [
    "print(\"Reproducing and expanding case study of Shvartser posted at Dr. Brownlee's machinelearningmastery.com\")\n",
    "\n",
    "import sklearn\n",
    "print(sklearn.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "UsageError: Line magic function `%sh` not found (But cell magic `%%sh` exists, did you mean that instead?).\n"
     ]
    }
   ],
   "source": [
    "%sh\n",
    "#need to run ***ONCE*** to install SMOTE package\n",
    "#/home/ubuntu/databricks/python/bin/pip install 'imbalanced-learn<0.2.1'\n",
    "#pip freeze | grep imbalanced-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# preproc imports\n",
    "import pandas\n",
    "from pandas.tools.plotting import scatter_matrix\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn import preprocessing as preproc\n",
    "import numpy\n",
    "from sklearn.utils import resample\n",
    "from imblearn.over_sampling import SMOTE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# algo eval imports\n",
    "from sklearn import model_selection\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.svm import SVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fine tuning\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# significance tests\n",
    "import scipy.stats as stats\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# build and save model using Pickle\n",
    "from random import *\n",
    "import pickle\n",
    "\n",
    "# final model\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import roc_curve, auc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "File b'/dbfs/FileStore/tables/diabetes.data' does not exist",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-13-3bc9f0b50227>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mdatafile\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"/dbfs/FileStore/tables/diabetes.data\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[0mheaders\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'preg'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'plas'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'pres'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'skin'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'test'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'mass'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'pedi'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'age'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'class'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[0mdataset\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mpandas\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdatafile\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnames\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mheaders\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36mparser_f\u001b[1;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, escapechar, comment, encoding, dialect, tupleize_cols, error_bad_lines, warn_bad_lines, skipfooter, skip_footer, doublequote, delim_whitespace, as_recarray, compact_ints, use_unsigned, low_memory, buffer_lines, memory_map, float_precision)\u001b[0m\n\u001b[0;32m    707\u001b[0m                     skip_blank_lines=skip_blank_lines)\n\u001b[0;32m    708\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 709\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    710\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    711\u001b[0m     \u001b[0mparser_f\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__name__\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36m_read\u001b[1;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[0;32m    447\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    448\u001b[0m     \u001b[1;31m# Create the parser.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 449\u001b[1;33m     \u001b[0mparser\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    450\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    451\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[0;32m    816\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'has_index_names'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mkwds\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'has_index_names'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    817\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 818\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    819\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    820\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[1;34m(self, engine)\u001b[0m\n\u001b[0;32m   1047\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_make_engine\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mengine\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'c'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1048\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m'c'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1049\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mCParserWrapper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1050\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1051\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m'python'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, src, **kwds)\u001b[0m\n\u001b[0;32m   1693\u001b[0m         \u001b[0mkwds\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'allow_leading_cols'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mindex_col\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1694\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1695\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_reader\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mparsers\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTextReader\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1696\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1697\u001b[0m         \u001b[1;31m# XXX\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader.__cinit__\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._setup_parser_source\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: File b'/dbfs/FileStore/tables/diabetes.data' does not exist"
     ]
    }
   ],
   "source": [
    "datafile=\"/dbfs/FileStore/tables/diabetes.data\"\n",
    "headers=['preg', 'plas', 'pres', 'skin', 'test', 'mass', 'pedi', 'age', 'class']\n",
    "dataset=pandas.read_csv(datafile, names=headers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\" = 3. Summarize the Dataset = \")\n",
    "# shape\n",
    "print(\" == 3.1 Dimensions of Dataset, shape of data == \")\n",
    "print(dataset.shape)\n",
    "\n",
    "# head\n",
    "print(\" == 3.2 Peek at the Data, head -- first 10 items == \")\n",
    "print(dataset.head(10))\n",
    "\n",
    "# data types\n",
    "print(\" == 3.a data types for each attributes == \")\n",
    "print(dataset.dtypes)\n",
    "\n",
    "# descriptions\n",
    "print(\" == 3.3 Statistical Summary == \")\n",
    "print(dataset.describe())\n",
    "\n",
    "# class distribution\n",
    "print(\" == 3.4 class distribution  ==\")\n",
    "print(dataset.groupby('class').size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\" = 4. Data Visualization = \")\n",
    "# box and whisker plots\n",
    "print(\" == 4.1 Univariate Plots: box and whisker plots. why? to determine outliers? = \")\n",
    "dataset.plot(kind='box', subplots=True, layout=(3,3), sharex=False, sharey=False)\n",
    "fig = plt.show()\n",
    "display(fig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# histograms\n",
    "print(\" == 4.1 Univariate Plots: histograms. why? to determine if the distribution is normal-like? == \")\n",
    "dataset.hist()\n",
    "fig=plt.show()\n",
    "display(fig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# scatter plot matrix\n",
    "print(\"== 4.2 Multivariate Plots: Multivariate Plots:scatter plot matrix. why? to spot structured relationships between input variables ==\")\n",
    "scatter_matrix(dataset)\n",
    "fig=plt.show()\n",
    "display(fig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "numpy.set_printoptions(precision=3)\n",
    "array = numpy.array(dataset.values)\n",
    "\n",
    "print(\"== 4.a Generating data sets ==\")\n",
    "\n",
    "print(\"diabetes_attr: unchanged, original attributes\")\n",
    "diabetes_attr = array[:,0:8]\n",
    "label = array[:,8] #unchanged across preprocessing?\n",
    "diabetes_df = pandas.DataFrame(diabetes_attr)\n",
    "\n",
    "print(\"normalized_attr: range of 0 to 1\")\n",
    "scaler = preproc.MinMaxScaler().fit(diabetes_attr)\n",
    "normalized_attr = scaler.transform(diabetes_attr)\n",
    "normalized_df = pandas.DataFrame(normalized_attr)\n",
    "#print(normalized_df.describe())\n",
    "\n",
    "print(\"standardized_attr: mean of 0 and stdev of 1\")\n",
    "#scaler = preproc.StandardScaler().fit(diabetes_attr)\n",
    "#standardized_attr = scaler.transform(diabetes_attr)\n",
    "standardized_attr = preproc.scale(diabetes_attr)\n",
    "standardized_df = pandas.DataFrame(standardized_attr)\n",
    "print(standardized_df.describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"== 4.b treating missing values by purging or imputating ==\")\n",
    "## missing.arff\n",
    "print(\"=== Assuming, zero indicates missing values === \")\n",
    "print(\"missing values by count\")\n",
    "print((dataset[['plas', 'pres', 'skin', 'test', 'mass', 'pedi', 'age']] == 0).sum())\n",
    "print(\"=== purging ===\")\n",
    "# make a copy of original data set\n",
    "dataset_cp = dataset.copy(deep=True)\n",
    "\n",
    "dataset_cp[['plas', 'pres', 'skin', 'test', 'mass']] = dataset_cp[['plas', 'pres', 'skin', 'test', 'mass']].replace(0, numpy.NaN)\n",
    "\n",
    "# print the first 10 rows of data\n",
    "print(dataset_cp.head(10))\n",
    "\n",
    "# count the number of NaN values in each column\n",
    "print(dataset_cp.isnull().sum())\n",
    "\n",
    "# dataset with missing values\n",
    "dataset_missing = dataset_cp.dropna()\n",
    "\n",
    "# summarize the number of rows and columns in the dataset\n",
    "print(dataset_cp.shape)\n",
    "\n",
    "missing_attr = numpy.array(dataset_missing.values[:,0:8])\n",
    "missing_label = numpy.array(dataset_missing.values[:,8])\n",
    "\n",
    "print(\"=== imputing by replacing missing values with mean column values ===\")\n",
    "\n",
    "dataset_impute = dataset_cp.fillna(dataset_cp.mean())\n",
    "# count the number of NaN values in each column\n",
    "print(dataset_impute.isnull().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"== 4.c addressing class imbalance under or over sampling ==\")\n",
    "\n",
    "impute_attr = numpy.array(dataset_impute.values[:,0:8])\n",
    "\n",
    "print(\"=== undersampling majority class by purging ===\")\n",
    "\n",
    "# Separate majority and minority classes\n",
    "df_majority = dataset[dataset['class']==0]\n",
    "df_minority = dataset[dataset['class']==1]\n",
    "\n",
    "print(\"df_minority['class'].size\", df_minority['class'].size)\n",
    "\n",
    "# Downsample majority class\n",
    "\n",
    "df_majority_downsampled = resample(df_majority, \n",
    "                          replace=False,    # sample without replacement\n",
    "                          n_samples=df_minority['class'].size,  # match minority class\n",
    "                          random_state=7) # reproducible results\n",
    " \n",
    "# Combine minority class with downsampled majority class\n",
    "df_downsampled = pandas.concat([df_majority_downsampled, df_minority])\n",
    " \n",
    "print(\"undersampled\", df_downsampled.groupby('class').size()) \n",
    "df_downsampled=df_downsampled.sample(frac=1).reset_index(drop=True)\n",
    "undersampling_attr = numpy.array(df_downsampled.values[:,0:8])\n",
    "undersampling_label = numpy.array(df_downsampled.values[:,8])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=== oversampling minority class with SMOTE ===\")\n",
    "\n",
    "sm = SMOTE(random_state=7)\n",
    "x_val = dataset.values[:,0:8]\n",
    "y_val = dataset.values[:,8]\n",
    "X_res, y_res = sm.fit_sample(x_val, y_val)\n",
    "\n",
    "features=['preg', 'plas', 'pres', 'skin', 'test', 'mass', 'pedi', 'age']\n",
    "oversampled_df = pandas.DataFrame(X_res)\n",
    "oversampled_df.columns = features\n",
    "oversampled_df = oversampled_df.assign(label = numpy.asarray(y_res))\n",
    "oversampled_df = oversampled_df.sample(frac=1).reset_index(drop=True)\n",
    "\n",
    "oversampling_attr = oversampled_df.values[:,0:8]\n",
    "oversampling_label = oversampled_df.values[:,8]\n",
    "\n",
    "print(\"oversampled_df\", oversampled_df.groupby('label').size()) \n",
    "\n",
    "\n",
    "print(\" = 5. Evaluate Some Algorithms = \")\n",
    "# Split-out validation dataset\n",
    "print(\" == 5.1 Create a Validation Dataset: Split-out validation dataset == \")\n",
    "\n",
    "# Test options and evaluation metric\n",
    "print(\" == 5.2 Test Harness: Test options and evaluation metric == \")\n",
    "seed = 7\n",
    "scoring = 'accuracy'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\" = 5. Evaluate Some Algorithms = \")\n",
    "\n",
    "# Split-out validation dataset\n",
    "print(\" == 5.1 Create a Validation Dataset: Split-out validation dataset == \")\n",
    "\n",
    "# Test options and evaluation metric\n",
    "print(\" == 5.2 Test Harness: Test options and evaluation metric == \")\n",
    "seed = 7\n",
    "scoring = 'accuracy'\n",
    "\n",
    "# Spot Check Algorithms\n",
    "print(\"== 5.3 Build Models: build and evaluate our five models, Spot Check Algorithms ==\")\n",
    "datasets = []\n",
    "datasets.append(('diabetes_attr', diabetes_attr, label))\n",
    "datasets.append(('normalized_attr', normalized_attr, label))\n",
    "datasets.append(('standardized_attr', standardized_attr, label))\n",
    "datasets.append(('impute_attr', impute_attr, label))\n",
    "datasets.append(('missing_attr', missing_attr, missing_label))\n",
    "datasets.append(('undersampling_attr', undersampling_attr, undersampling_label))\n",
    "datasets.append(('oversampling_attr', oversampling_attr, oversampling_label))\n",
    "\n",
    "models = []\n",
    "models.append(('LR', LogisticRegression())) # based on imbalanced datasets and default parameters\n",
    "models.append(('LDA', LinearDiscriminantAnalysis()))\n",
    "models.append(('KNN', KNeighborsClassifier()))\n",
    "models.append(('CART', DecisionTreeClassifier()))\n",
    "models.append(('NB', GaussianNB()))\n",
    "models.append(('RF', RandomForestClassifier()))\n",
    "models.append(('SVM', SVC()))\n",
    "\n",
    "print(\"eval metric: \" + scoring)\n",
    "for dataname, attributes, target in datasets:\n",
    "\t# evaluate each model in turn\n",
    "\tresults = []\n",
    "\tnames = []\n",
    "\tprint(\"= \" + dataname + \" = \")\n",
    "\tprint(\"algorithm,mean,std,signficance,p-val\")\n",
    "\tfor name, model in models:\n",
    "\t\tkfold = model_selection.KFold(n_splits=10, random_state=seed)\n",
    "\t\tcv_results = model_selection.cross_val_score(model, attributes, target, cv=kfold, scoring=scoring)\n",
    "\t\tresults.append(cv_results)\n",
    "\t\t#print(\"cv_results\")\n",
    "\t\t#print(cv_results)\n",
    "\t\tnames.append(name)\n",
    "\t\t\n",
    "\t\tt, prob = stats.ttest_rel(a= cv_results,b= results[0])\n",
    "\t\t#print(\"LR vs \", name, t,prob)\n",
    "\t\t# Below 0.05, significant. Over 0.05, not significant. \n",
    "\t\t# http://blog.minitab.com/blog/understanding-statistics/what-can-you-say-when-your-p-value-is-greater-than-005\n",
    "\t\tstatistically_different = (prob < 0.05)\n",
    "\t\t\n",
    "\t\tmsg = \"%s: %f (%f) %s %f\" % (name, cv_results.mean(), cv_results.std(), statistically_different, prob)\n",
    "\t\tprint(msg)\n",
    "\n",
    "\t# Compare Algorithms\n",
    "\tprint(\" == 5.4 Select Best Model, Compare Algorithms == \")\n",
    "\tfig = plt.figure()\n",
    "\tfig.suptitle('Algorithm Comparison for ' + dataname)\n",
    "\tax = fig.add_subplot(111) # what does 111 mean?\n",
    "\tplt.boxplot(results)\n",
    "\tplt.ylabel(scoring)\n",
    "\tax.set_xticklabels(names)\n",
    "\tfig = plt.show()\n",
    "\t#display()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_size = 0.33\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(diabetes_attr, label, test_size=test_size,\n",
    "random_state=seed)\n",
    "\n",
    "param_grid = {'C': [0.001, 0.01, 0.1, 1, 10, 100, 1000], 'penalty': ['l2','l1']}\n",
    "logr = GridSearchCV(LogisticRegression(class_weight='balanced'), param_grid, scoring='accuracy')\n",
    "logr.fit(X_train, Y_train)\n",
    "print(\"logr.best_score=\",logr.best_score_)\n",
    "print(\"logr.best_estimator_.C=\",logr.best_estimator_.C)\n",
    "print(\"logr.best_estimator_.penalty=\",logr.best_estimator_.penalty)\n",
    "\n",
    "#building model for baseline\n",
    "model = LogisticRegression(class_weight='balanced')\n",
    "y_score = model.fit(diabetes_attr, label)\n",
    "result = model.score(X_test, Y_test) # determine r2 value\n",
    "print(\"baseline accuracy on X_test without grid search=\",result)\n",
    "\n",
    "#building model with grid search selected parameters\n",
    "model = LogisticRegression(class_weight='balanced',C=logr.best_estimator_.C, penalty=logr.best_estimator_.penalty)\n",
    "y_score = model.fit(diabetes_attr, label)\n",
    "result = model.score(X_test, Y_test) # determine r2 value\n",
    "print(\"accuracy with grid search selected C and penalty_model, and before storing to disk\", result)\n",
    "\n",
    "# save the model to disk\n",
    "filename = 'diabetes_py_model.sav' \n",
    "pickle.dump(model, open(filename, 'wb'))\n",
    "# some time later...\n",
    "# load the model from disk\n",
    "loaded_model = pickle.load(open(filename, 'rb')) \n",
    "result = loaded_model.score(X_test, Y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save the model to disk\n",
    "filename = 'diabetes_py_model.sav' \n",
    "pickle.dump(model, open(filename, 'wb'))\n",
    "# some time later...\n",
    "# load the model from disk\n",
    "loaded_model = pickle.load(open(filename, 'rb')) \n",
    "result = loaded_model.score(X_test, Y_test)\n",
    "\n",
    "print(\"accuracy on X_test after loading from disk=\",result)\n",
    "\n",
    "delta0_predictions=loaded_model.predict(X_test)\n",
    "print(\"delta0_predictions\")\n",
    "print(\"accuracy_score=\",accuracy_score(Y_test, delta0_predictions))\n",
    "tn, fp, fn, tp=confusion_matrix(Y_test, delta0_predictions).ravel()\n",
    "print(\"tn, fp, fn, tp:\", tn, fp, fn, tp)\n",
    "sensitivity_tpr = float(tp)/(float(tp)+float(fp))\n",
    "specificity_tnr = float(tn)/(float(tn)+float(fp))\n",
    "print(\"sensitivity_tpr,specificity_tnr:\", sensitivity_tpr,specificity_tnr)\n",
    "print(classification_report(Y_test, delta0_predictions))\n",
    "\n",
    "delta0_probs=loaded_model.predict_proba(X_test)\n",
    "fpr, tpr, thresholds = roc_curve(Y_test, delta0_probs[:, 1])\n",
    "roc_auc = auc(fpr, tpr)\n",
    "print(\"delta0_roc_auc:\", roc_auc)\n",
    "\n",
    "plt.figure()\n",
    "lw = 2\n",
    "plt.plot(fpr, tpr, color='darkorange',\n",
    "         lw=lw, label='ROC curve (area = %0.2f)' % roc_auc)\n",
    "plt.plot([0, 1], [0, 1], color='navy', lw=lw, linestyle='--')\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.05])\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('Positive Test ROC')\n",
    "plt.legend(loc=\"lower right\")\n",
    "fig = plt.show()\n",
    "display()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"loaded_model.self.classes_\",loaded_model.classes_)\n",
    "delta_range=[-.02, 0, 0.02, 0.04, 0.06, 0.08, .10, .12]\n",
    "i=0\n",
    "sensitivity_tpr=[0.0] * len(delta_range)\n",
    "specificity_tnr=[0.0] * len(delta_range)\n",
    "for delta in delta_range:\t\n",
    "\tprobs=loaded_model.predict_proba(X_test)\n",
    "\treport = [[ins[0], ins[1], 1] if (ins[1] > (ins[0]+delta)) else [ins[0], ins[1], 0] for ins in probs]\n",
    "\treport_df = pandas.DataFrame(report, columns=['neg_prob','pos_prob','pred'])\n",
    "\tpredictions = numpy.array(report_df.values)[:,2]\n",
    "\ttn, fp, fn, tp=confusion_matrix(Y_test, predictions).ravel()\n",
    "\tsensitivity_tpr[i]= float(tp)/(float(tp)+float(fn))\n",
    "\tspecificity_tnr[i]= float(tn)/(float(tn)+float(fp))\n",
    "\tprint(\"deltaX,sensitivity_tpr,specificity_tnr:\", delta, sensitivity_tpr[i],specificity_tnr[i]) \n",
    "\t#print(\"accuracy_score=\",accuracy_score(Y_test, predictions))\n",
    "\tprint(\"confusion_matrix: tn, fp, fn, tp:\", tn, fp, fn, tp)\n",
    "\t#print(classification_report(Y_test, predictions))\n",
    "\ti=i+1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib.legend_handler import HandlerLine2D\n",
    "\n",
    "plt.clf()\n",
    "pred_legend,=plt.plot(delta_range, sensitivity_tpr, 'r', marker='x', label=\"sensitivity,tpr\") \n",
    "prob_legend,=plt.plot(delta_range, specificity_tnr, 'b', linestyle='--', marker='o', label=\"specificity,tnr\")\n",
    "plt.legend(handler_map={pred_legend: HandlerLine2D(numpoints=4)})\n",
    "plt.xlabel('delta')\n",
    "plt.ylabel('rate(0-1)')\n",
    "plt.show()\n",
    "display()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "delta=-0.10\n",
    "print(\"cross-over of sensitivity and specificity lie at about delta=\", delta)\n",
    "report=[[ins[0], ins[1], 1] if (ins[1] > (ins[0]+delta)) else [ins[0], ins[1], 0] for ins in probs]\n",
    "report_df=pandas.DataFrame(report, columns=['neg_prob','pos_prob','pred'])\n",
    "predictions=numpy.array(report_df.values)[:,2]\n",
    "positive_prob=numpy.array(report_df.values)[:,1]\n",
    "\n",
    "print(\"accuracy_score=\",accuracy_score(Y_test, predictions))\n",
    "tn, fp, fn, tp=confusion_matrix(Y_test, predictions).ravel()\n",
    "print(\"confusion_matrix: tn, fp, fn, tp:\", tn, fp, fn, tp)\n",
    "sensitivity_tpr= float(tp)/(float(tp)+float(fn))\n",
    "specificity_tnr= float(tn)/(float(tn)+float(fp))\n",
    "print(\"deltaX,sensitivity_tpr,specificity_tnr:\", delta, sensitivity_tpr,specificity_tnr) \n",
    "print(classification_report(Y_test, predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sort instances by (a) class, and then (b) positive probability for plotting\n",
    "report_df=report_df.sort_values(by=['pred','pos_prob'])\n",
    "predictions=numpy.array(report_df.values)[:,2]\n",
    "positive_prob=numpy.array(report_df.values)[:,1]\n",
    "\n",
    "plt.clf()\n",
    "pred_legend,=plt.plot(predictions, 'r', label=\"prediction\") \n",
    "prob_legend,=plt.plot(positive_prob, 'b', label=\"+ve probability\")\n",
    "\n",
    "plt.legend(handler_map={pred_legend: HandlerLine2D(numpoints=4)})\n",
    "plt.xlabel('instance#')\n",
    "plt.ylabel('probability(0-1)')\n",
    "\n",
    "plt.show()\n",
    "display()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  },
  "name": "diabetes",
  "notebookId": 2246037980686797
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
